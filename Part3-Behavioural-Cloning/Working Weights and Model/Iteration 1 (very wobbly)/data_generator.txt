### THIS IS A WORKING VERSION ###

def data_generator_1(data): 
    
    # Define the parameters for data manipulation
    TRANS_X_RANGE = 100
    TRANS_Y_RANGE = 0
    TRANS_ANGLE = 0.15
    CAMERA_STEERING_ANGLE_OFFSET = 0.3
    CROP_X1, CROP_Y1, CROP_X2, CROP_Y2 = 50,40,270,120
    
    # Get the image and steering
    path = data.image_path
    camera = path.split('/')[1].split("_")[0] # see if it is left, center or right
    steering_angle = data.steering

    # Show the image
    image_data = mpimg.imread(path)

    # Randomly compute a X,Y translation    

    # -TRANS_X_RANGE/2 <= x_translation <= TRANS_X_RANGE/2 so -50 to 50
    x_translation = (TRANS_X_RANGE * np.random.uniform()) - (TRANS_X_RANGE / 2) 

    # -TRANS_Y_RANGE/2 <= y_translation <= TRANS_Y_RANGE/2 so -20 to 20
    y_translation = (TRANS_Y_RANGE * np.random.uniform()) - (TRANS_Y_RANGE / 2)

    # Do the translation
    image_data = translate_image(image_data, x_translation, y_translation)

    # Calculate the new angle

    # Note here that if we translate left, then we would need to increase steering
    # Think of it as we are closer to the obstacle on the left, and vice versa for translate right
    new_steering_angle =  steering_angle + ((x_translation/TRANS_X_RANGE) * 2) * TRANS_ANGLE
    
    if camera == "left":
        new_steering_angle += CAMERA_STEERING_ANGLE_OFFSET
    elif camera == "right":
        new_steering_angle -= CAMERA_STEERING_ANGLE_OFFSET
    else:
        new_steering_angle = new_steering_angle

    # Now to make sure we can generalize to both left and right side 
    if np.random.uniform() <= 0.5:
        image_data = np.fliplr(image_data)
        new_steering_angle = -new_steering_angle
    
    # Crop the image
    image_data = crop_image(image_data, CROP_X1, CROP_Y1, CROP_X2, CROP_Y2)
    
    return(image_data, new_steering_angle)

from keras.models import Sequential
from keras.layers.core import Dense, Activation, Flatten, Dropout
from keras.layers.convolutional import Convolution1D, Convolution2D, MaxPooling2D
from keras.activations import relu, softmax
from IPython.display import SVG, display
from keras.utils.visualize_util import model_to_dot
import keras

def get_nvidia_model():
    model = Sequential()

    model.add(Convolution2D(24, 5, 5, border_mode = "valid", subsample = (2,2), input_shape = (80,220,3)))
    model.add(Activation('relu'))

    model.add(Convolution2D(36, 5, 5, border_mode = "valid", subsample = (2,2)))
    model.add(Activation('relu'))

    model.add(Convolution2D(48, 5, 5, border_mode = "valid", subsample = (2,2)))
    model.add(Activation('relu'))

    model.add(Convolution2D(64, 3, 3, border_mode = "valid", subsample = (1,1)))
    model.add(Activation('relu'))

    model.add(Convolution2D(64, 3, 3, border_mode = "valid", subsample = (1,1)))
    model.add(Activation('relu'))

    model.add(Flatten())

    # Now use fully connected layers 
    model.add(Activation('relu'))
    model.add(Dropout(0.25))

    model.add(Activation('relu'))
    model.add(Dense(100))
    model.add(Activation('relu'))
    model.add(Dense(50))
    model.add(Activation('relu'))
    model.add(Dense(10))
    model.add(Activation('relu'))

    # Add the output layer
    model.add(Dense(1, init = 'normal'))

    # Define the optimizer
    adam = keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0) 
    
    # Compile the model
    model.compile(loss = 'mean_squared_error', optimizer = adam)
    return(model)

model = get_nvidia_model()
# Show the model
display(SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg')))

# Example use:
n_times = 60000
discard_prob = 0.5
discard_range = (-0.1, 0.1)
new_df = create_data_set(df, data_generator_1, n_times, discard_prob, discard_range)
